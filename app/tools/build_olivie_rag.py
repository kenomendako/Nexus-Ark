#!/usr/bin/env python3
"""
é…å¸ƒç”¨ãƒšãƒ«ã‚½ãƒŠï¼ˆã‚ªãƒªãƒ´ã‚§ï¼‰ã®RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨æ–¹æ³•: 
  uv run tools/build_olivie_rag.py
"""
import os
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(script_dir)
sys.path.insert(0, project_root)

def build_olivie_rag():
    """é…å¸ƒç”¨ã‚ªãƒªãƒ´ã‚§ã®RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰"""
    print("ğŸ§  Building RAG index for Olivie (sample persona)...")
    
    # å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆé…å»¶ãƒ­ãƒ¼ãƒ‰ï¼‰
    import config_manager
    from langchain_google_genai import GoogleGenerativeAIEmbeddings
    from langchain_community.vectorstores import FAISS
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_community.document_loaders import TextLoader
    
    # é…å¸ƒç”¨ãƒšãƒ«ã‚½ãƒŠã®ãƒ‘ã‚¹
    olivie_dir = Path(project_root) / "assets" / "sample_persona" / "Olivie"
    knowledge_dir = olivie_dir / "knowledge"
    rag_data_dir = olivie_dir / "rag_data"
    faiss_index_dir = rag_data_dir / "faiss_index"
    
    if not knowledge_dir.exists():
        print(f"âŒ Knowledge directory not found: {knowledge_dir}")
        return False
    
    # çŸ¥è­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    knowledge_files = list(knowledge_dir.glob("*.md")) + list(knowledge_dir.glob("*.txt"))
    print(f"ğŸ“š Found {len(knowledge_files)} knowledge file(s):")
    for f in knowledge_files:
        print(f"   - {f.name} ({f.stat().st_size:,} bytes)")
    
    if not knowledge_files:
        print("âŒ No knowledge files found")
        return False
    
    # APIã‚­ãƒ¼ã®ç¢ºèªï¼ˆconfig.jsonã‹ã‚‰ç›´æ¥èª­ã¿è¾¼ã¿ï¼‰
    import json
    config_path = Path(project_root) / "config.json"
    api_key = None
    
    if config_path.exists():
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            gemini_keys = config.get("gemini_api_keys", {})
            for key_name, key_value in gemini_keys.items():
                if key_value and not key_value.startswith("YOUR_"):
                    api_key = key_value
                    print(f"ğŸ”‘ Using API key: {key_name}")
                    break
        except Exception as e:
            print(f"âš ï¸ Failed to read config.json: {e}")
    
    if not api_key:
        print("âŒ No valid Gemini API key found")
        return False
    
    try:
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿
        print("ğŸ“– Loading documents...")
        documents = []
        for file_path in knowledge_files:
            try:
                loader = TextLoader(str(file_path), encoding='utf-8')
                documents.extend(loader.load())
            except Exception as e:
                print(f"   âš ï¸ Failed to load {file_path.name}: {e}")
        
        if not documents:
            print("âŒ No documents loaded")
            return False
        
        print(f"   Loaded {len(documents)} document(s)")
        
        # ãƒ†ã‚­ã‚¹ãƒˆã®åˆ†å‰²
        print("âœ‚ï¸ Splitting text...")
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n## ", "\n### ", "\n#### ", "\n\n", "\n", " ", ""]
        )
        splits = text_splitter.split_documents(documents)
        print(f"   Created {len(splits)} chunks")
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã®åˆæœŸåŒ–
        print("ğŸ”® Initializing embeddings...")
        embeddings = GoogleGenerativeAIEmbeddings(
            model="models/gemini-embedding-001",
            google_api_key=api_key
        )
        
        # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ§‹ç¯‰
        print("âš™ï¸ Building FAISS index...")
        vectorstore = FAISS.from_documents(splits, embeddings)
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä¿å­˜
        faiss_index_dir.mkdir(parents=True, exist_ok=True)
        vectorstore.save_local(str(faiss_index_dir))
        
        # çµæœç¢ºèª
        index_file = faiss_index_dir / "index.faiss"
        if index_file.exists():
            size = index_file.stat().st_size
            print(f"âœ… Successfully built RAG index ({size:,} bytes)")
            print(f"   Location: {faiss_index_dir}")
            return True
        else:
            print("âŒ Index file not created")
            return False
            
    except Exception as e:
        print(f"âŒ Error building index: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = build_olivie_rag()
    sys.exit(0 if success else 1)
